{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mathLab](http://people.sissa.it/~heltai/sites/default/files/photos/logo-\n",
    "mathlab-lungo.png)\n",
    "\n",
    "# Applied Mathematics: an Introduction to Scientific Computing\n",
    "\n",
    "Prof. Luca HELTAI\n",
    "\n",
    "Prof. Gianluigi ROZZA\n",
    "\n",
    "\n",
    "## Basic Principles\n",
    "\n",
    "Numerical Analysis is the *“art of approximating”*. Quoting Wikipedia:\n",
    "\n",
    "> An approximation is an inexact representation of something that is\n",
    "> still close enough to be useful. Although approximation is most often\n",
    "> applied to numbers, it is also frequently applied to such things as\n",
    "> mathematical functions, shapes, and physical laws.\n",
    "\n",
    "Approximations should be used when incomplete information prevents use\n",
    "of exact representations. Many problems in physics are either too\n",
    "complex to solve analytically, or impossible to solve using the\n",
    "available analytical tools. Thus, even when the exact representation is\n",
    "known, an approximation may yield a sufficiently accurate solution while\n",
    "reducing the complexity of the problem significantly.\n",
    "\n",
    "The type of approximation used depends on the available information, the\n",
    "degree of accuracy required, the sensitivity of the problem to this\n",
    "data, and the savings (usually in time and effort) that can be achieved\n",
    "by approximation.\n",
    "\n",
    "In this course we focus on three main aspects:\n",
    "\n",
    "- Methodologies (or approximation algorithms)\n",
    "- Analysis (estimate errors and convergence properties)\n",
    "- Implementation (through python and numpy notebooks)\n",
    "\n",
    "Approximation is a matter of \n",
    "\n",
    "- Representation (floating point values VS real numbers, finite dimensional \n",
    "  spaces VS infinite dimensional ones, etc.)\n",
    "- Measure of the Error (how do we know that we did a good job in approximating?)\n",
    "\n",
    "In general, we will end up working with $R^n$. We recall here some basi principles:\n",
    "\n",
    "### Norms of vectors, matrices and functions\n",
    "\n",
    "Given a vector space $V$ over the field of real ${\\mathbb{R}^{}}$ or\n",
    "complex numbers ${\\mathbb{C}^{}}$ ($V$ might be infinite dimensional), a\n",
    "*semi-norm* on $V$ is a function ${|\\cdot|}: V\\rightarrow\n",
    "{\\mathbb{C}^{}}$ satisfying:\n",
    "\n",
    "1.  ${|c f|}={|c|}{|f|}$, for all\n",
    "    $c\\in {\\mathbb{C}^{}}$;\n",
    "\n",
    "2.  ${|f+g|}\\le {|f|}+{|g|}$ (often known\n",
    "    as triangle inequality).\n",
    "\n",
    "As it can be easily seen (1)–(2) imply that the norm is always\n",
    "non-negative: $$0=0\\cdot{|f|}={|0\\cdot f|}=\n",
    "{|(1-1)f|}={|f-f|}\\le{|f|}+{|(-1)f|}=2{\\\n",
    "|f|}.$$\n",
    "The semi-norm becomes a *norm* if in addition to (1)–(2) we have also\n",
    "that for all $f\\in V$\n",
    "\n",
    "1.  ${|f|}=0$ if and only if $f=0$,\n",
    "\n",
    "A complete vector space with a norm is called a *Banach space*.\n",
    "\n",
    "An inner product is any sesquilinear function\n",
    "$(\\cdot,\\cdot):V\\times V\\mapsto {\\mathbb{C}^{}}$ satisfying the\n",
    "following conditions:\n",
    "\n",
    "1.  $(f,g)=\\overline{(g,f)}$;\n",
    "\n",
    "2.  $(f,f)\\ge 0$; $(f,f)=0$ if and only if $f=0$;\n",
    "\n",
    "3.  $(\\alpha f,g)=\\alpha (f,g)$ for all $\\alpha\\in {\\mathbb{C}^{}}$;\n",
    "\n",
    "4.  $(f+g,h)=(f,h)+(g,h)$.\n",
    "\n",
    "The norm is then defined as $\\|f\\|^2=(f,f)$. That this is a norm (i.e.\n",
    "satisfies the triangle inequality) is proved by first proving the\n",
    "*Cauchy-Schwarz* inequality\n",
    "$$|(f,g)| \\le \\sqrt{(f,f)(g,g)}.$$ The proof of the latter is as\n",
    "follows: For any $\\alpha\\in {\\mathbb{C}^{}}$ we have that\n",
    "$$0\\le (f-\\alpha g,f-\\alpha g)=(f,f)-\\alpha(g,f)-\\overline{\\alpha}(f,g)+\n",
    "{|\\alpha|}^2(g,g).$$ If $g=0$ then the inequality is obviously\n",
    "true. If $g\\neq 0$ we choose $\\alpha=\\frac{(f,g)}{(g,g)}$ to obtain the\n",
    "following $$0\\le (f,f)-\\frac{|(f,g)|^2}{(g,g)}.$$ The triangle\n",
    "inequality then follows from the Schwarz inequality\n",
    "$$(f+g,f+g)=\\|f+g\\|^2=\\|f\\|^2+\\|g\\|^2+{\\rm Re}[(f,g)]\\le(\\|f\\|+\\|g\\|)^2.$$\n",
    "A Banach space with inner product and a norm induced by this product is\n",
    "called a *Hilbert space*.\n",
    "\n",
    "Here are some examples of norms and semi-norms:\n",
    "\n",
    "\n",
    "**lp** $V={\\mathbb{R}^{n}}$, and for any $x\\in V$, its $\\ell_p$ norm\n",
    "is defined as $$\\begin{aligned}\n",
    "\\|x\\|^p_{p}&=&\\sum_{i=1}^n {|x_i|}^p, \\quad 1\\le p  < \\infty,\\\\\n",
    "\\|x\\|_{\\infty}&=&\\sup_{1\\le i\\le n} {|x_i|}. \\end{aligned}$$\n",
    "Replacing $n$ by $\\infty$ in the above equations leads to the definition\n",
    "of a Banach space denoted usually with $\\ell_p$, with elements finite or\n",
    "infinite sequences for which $$\\begin{aligned}\n",
    "\\|x\\|^p_{p}&=&\\sum_{i} {|x_i|}^p, \\quad 1\\le p  < \\infty,\\\\\n",
    "\\|x\\|_{\\infty}&=&\\sup_{i} {|x_i|}. \\end{aligned}$$ are finite.\n",
    "\n",
    "**LP** Let $I=(a,b)$. Then $L_p(I)$ is defined as the vector space of\n",
    "measurable functions $f$, for which $$\\begin{aligned}\n",
    "\\|f\\|_p&:=&\\left(\\int_I |f|^p\\;dx\\right)^{1/p} <\\infty, \\quad 1\\le p <\n",
    "\\infty,\\\\\n",
    "\\|f\\|_\\infty&:=&{\\rm ess }\\sup_{x\\in I} |f(x)| < \\infty,\n",
    "\\quad p = \\infty.\\end{aligned}$$ That the quantity defined in\n",
    "Example \\[ex:LP\\] is a norm one can show by using Hölder’s and\n",
    "Minkowski’s inequalities, which are as follows: Let $1\\le p \\le \\infty$,\n",
    "and $q$ is the conjugate exponent to $p$ (i.e. $p^{-1}+q^{-1}=1$, with\n",
    "$q=\\infty$, when $p=1$). Then $$\\begin{aligned}\n",
    "\\|fg\\|_1\\le \\|f\\|_p\\|g\\|_q, &\\quad \\mbox{(Hölder's inequality)}\\\\\n",
    "\\|f+g\\|_p\\le \\|f\\|_p+\\|g\\|_p, &\\quad \\mbox{(Minkowski's\n",
    "inequality)}.\\end{aligned}$$\n",
    "Note that for $p=q=2$ the Hölder’s inequality is same as Schwarz\n",
    "inequality, by defining the inner product in $L_2$ as\n",
    "$$(f,g) := \\int_I f(x)g(x)\\;dx.$$ Also note that the Minkowski’s\n",
    "inequality is the triangle inequality in $L_p$. Similar inequalities\n",
    "hold true if the integrals are replaced by finite or infinite sums, and\n",
    "we also have Hölder’s and Minkowski’s inequalities for the spaces\n",
    "considered in example \\[ex:lp\\].\n",
    "\n",
    "\n",
    "**CK** Let $I=[a,b]$ and $C^k(I)$ $k\\in \\mathbb{N}$ be the vector\n",
    "space of functions, whose derivatives of order $\\le k$ are continuous. A\n",
    "(semi)-norm in $C^k(I)$ are then defined as\n",
    "$${|f|}_{k,\\infty}=\\|f^{(k)}\\|_\\infty=\\sup_{x\\in\n",
    "I}{|f^{(k)}(x)|}, \\quad\n",
    "\\|f\\|_{W^k_\\infty(I)}=\\sup_{0\\le i\\le k}{|f|}_{i,\\infty,I}.$$\n",
    "\n",
    "**WKP** For $1\\le p < \\infty$, and $k\\in \\mathbb{N}$ we define the\n",
    "*Sobolev (semi)-norm*, as follows:\n",
    "$${|f|}_{k,p,I}:=\\|f^{(k)}\\|_{0,p,I}=\\|f^{(k)}\\|_p, \\quad\n",
    "\\|f\\|_{k,p,I}:=\\left(\\sum_{0\\le i\\le k}|f|^p_{i,p,I}\\right)^{1/p}$$ The\n",
    "functions with finite Sobolev norm form the Banach space $W_p^k(I)$.\n",
    "\n",
    "The examples above introduce several classes of Banach spaces,\n",
    "$C^{k}(I)$, $L_p(I)$ and $W_p^k$. They have a strightforward\n",
    "generalizations to higher dimensions.\n",
    "\n",
    "For the normed finite dimensional spaces, the following result holds.\n",
    "\n",
    ">Let $V$ be a finite dimensional vector space. Then all\n",
    "> norms in $V$ are equivalent.\n",
    "\n",
    "and\n",
    "\n",
    "> Every finite dimensional space is closed.\n",
    "\n",
    "\n",
    "### Stability\n",
    "\n",
    "In an abstract setting, we describe a generic problem as\n",
    "$$\n",
    "  F(x,d) = 0\n",
    "$$\n",
    "where $x$ is the unknown (generally a real number, a\n",
    "vector or a function) and $d \\in D$ is the data. For each of the\n",
    "elements above we use an appropriate\n",
    "norm (see Lecture norms for a short introduction on\n",
    "norms and vector spaces), which will enable us to measure quantities of\n",
    "interests from a numerical point of view, such as errors, stability, and\n",
    "dependency of the solution from the data. In particular we will use the\n",
    "symbols $\\| \\cdot \\|_F$, $\\| \\cdot \\|_x$ and $\\| \\cdot\n",
    "\\|_d$ to indicate the various norms.\n",
    "\n",
    "In general, not all problems can be approximated. If we write a problem\n",
    "as above, then its approximation is\n",
    "useful only if the continuous problem has a unique solution which\n",
    "depends continuously on the data. We call these problems *well posed* or\n",
    "*stable*:\n",
    "\n",
    "\\[def:cont-stability\\] A mathematical problem is *well posed* or\n",
    "*stable* if the following properties are satisfied:\n",
    "\n",
    "-   Uniqueness of solutions:\n",
    "$$\n",
    "\\forall d \\in D, \\exists! \\, x \\text{ s.t. } F(x,d) = 0.\n",
    "$$\n",
    "\n",
    "-   Continuous dependence on data:\n",
    "\n",
    "Let $\\delta d$ be a perturbation of the data, such that $d+\\delta d\n",
    "  \\in D$, and let $x +\\delta x$ be the corresponding perturbed\n",
    "solution, i.e., $F(x+\\delta x, d+\\delta d) = 0$, then\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "  & \\forall d \\in D, \\quad \\exists\n",
    "  \\eta_0(d), K_0 \\text{ s.t. } \\\\\n",
    "  & \\| \\delta d \\|_d < \\eta_0  \\in D \\quad \\Longrightarrow \\quad \\| \\delta x\n",
    "\\|_x < K_0\n",
    "  \\| \\delta d \\|_d.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "### Condition numbers\n",
    "\n",
    "A measure of how accurately we can approximate the problem at hand, is\n",
    "then given by the *Condition Number*:\n",
    "\n",
    "*Relative* condition number:\n",
    "\n",
    "$$\n",
    "K := \\sup_{\\delta d \\text{ s.t. } d+\\delta d \\in D}\n",
    "\\frac{\\|\\delta x\\|_x/\\| x \\|_x}{\\|\\delta d\\|_d/\\| d \\|_d}.\n",
    "$$\n",
    "\n",
    "*Absolute* condition number (to be used when either $\\| x \\|_x\n",
    "  = 0$ or $\\| d \\|_d = 0$):\n",
    "\n",
    "$$\n",
    "K_{abs} := \\sup_{\\delta d \\text{ s.t. } d+\\delta d \\in D}\n",
    "\\frac{\\|\\delta x\\|_x}{\\|\\delta d\\|_d}.\n",
    "$$\n",
    "\n",
    "If there exist a unique solution $x$ to each data $d$, then we can\n",
    "construct a *resolvent map* $G$ such that $G(d) = x$ and $F(G(d),d)=0$.\n",
    "Assuming that $G$ is differentiable, then a Taylor expansion of $G$\n",
    "around $d$ allows us to express the condition numbers as\n",
    "\n",
    "$$\n",
    "K \\simeq \\| G'(d) \\| \\frac{\\| d \\|_d}{\\| G(d) \\|_x}.\n",
    "$$ and\n",
    "\n",
    "$$\n",
    "K_{abs} \\simeq \\| G'(d) \\|.\n",
    "$$\n",
    "\n",
    "A *stable* problem is *well conditioned* when its condition number is\n",
    "“small”, where the meaning of “small” depends on the problem at hand.\n",
    "\n",
    "### Numerical stability\n",
    "\n",
    "Once we have a *stable* problem, its approximation is usually given by a\n",
    "sequence of approximating problems\n",
    "\n",
    "$$\n",
    "  F_n(x_n, d_n) = 0, \\qquad n \\geq 1\n",
    "$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "& \\lim_{n \\to \\infty}  \\| F_n  - F \\|_F = 0  \\\\\n",
    "& \\lim_{n \\to \\infty}  \\| x_n  - x \\|_x = 0  \\\\\n",
    "& \\lim_{n \\to \\infty}  \\| d_n  - d \\|_d = 0  ,\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "for some appropriate norms.\n",
    "\n",
    "Equivalently to what happens in the continuous case, we can establish\n",
    "the stability of the approximate $n$-th problem.\n",
    "\n",
    "A mathematical approximation of a stable problem is itself *stable* if\n",
    "the following properties are satisfied:\n",
    "\n",
    "-   Uniqueness of solutions:\n",
    "$$\n",
    "\\forall n \\geq 1, \\forall d_n \\in D_n, \\exists! \\, x_n \\text{ s.t. }\n",
    "F_n(x_n,d_n) = 0.\n",
    "$$\n",
    "\n",
    "-   Continuous dependence on data:\n",
    "\n",
    "Let $\\delta d_n$ be a perturbation of the data, such that\n",
    "$d_n+\\delta d_n\n",
    "  \\in D_n$, and let $x_n +\\delta x_n$ be the corresponding perturbed\n",
    "solution, i.e., $F_n(x_n+\\delta x_n, d_n+\\delta d_n) = 0$, then\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "& \\forall d_n \\in D_n, \\quad \\exists\n",
    "\\eta_n(d), K_n \\text{ s.t. } \\\\\n",
    "& \\| \\delta d_n \\|_d < \\eta_n  \\in D_n \\quad \\Longrightarrow \\quad \\| \\delta x_n\n",
    "\\|_x < K_n\n",
    "\\| \\delta d_n \\|_d.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "### Consistency\n",
    "\n",
    "Whenever the data $d$ is admissible for $F_n$, then further properties\n",
    "of the approximations can be devised. In particular,\n",
    "\n",
    "A numerical problem is *consistent*, when, assuming $d \\in\n",
    "  D_n \\quad \\forall n$,\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} F_n (x, d)  =\n",
    "\\lim_{n \\to \\infty} F_n (x, d) - F(x,d) = 0.\n",
    "$$\n",
    "\n",
    "Moreover,\n",
    "\n",
    "A numerical approximation is *strongly consistent* when\n",
    "$$\n",
    "F_n(x,d) = 0, \\qquad \\forall n.\n",
    "$$\n",
    "\n",
    "### Convergence\n",
    "\n",
    "A numerical method is *convergent* when\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "& \\forall \\varepsilon > 0, \\qquad \\exists \\, n_0(\\varepsilon),\n",
    "\\exists\\,\n",
    "\\delta(\\varepsilon, n_0) \\text{ s.t. } \\\\\n",
    "& \\forall n > n_0, \\quad \\forall \\delta d_n : \\| \\delta d_n \\|_d\n",
    "< \\delta \\quad \\Longrightarrow \\quad \\| x(d) - x_n(d +\n",
    "\\delta d_n) \\| < \\varepsilon,\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where $x(d)$ is the solution to $F(x,d)=0$ and\n",
    "$x_n(d+\\delta d_n)$ is the solution to $F_n(x_n, d+\\delta d_n)$.\n",
    "\n",
    "**A convergent approximation is always stable.**\n",
    "\n",
    "### Lax-Richtmyer theorem\n",
    "\n",
    "One of the fundamental theorem of numerical analysis is the so called\n",
    "Lax-Richtmyer theorem:\n",
    "\n",
    ">If a problem is consistent, then stability and\n",
    ">convergence are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Stable Problems\n",
    "\n",
    "The problem of finding the solution $x \\in R^n$ to the linear system of equations $Ax = d$, where $d\\in R^n$ and $A\\in R^{n\\times n}$ can be written in the form $F(x,d) = 0$ simply by defining $F(x,d) := Ax-d$. \n",
    "\n",
    "These problems are well defined if and only if the matrix $A$ is invertible. In these cases, the resolvant $G(x)$ is the multiplication with the inverse of the matrix itself, i.e., if $F(G(d), d) =0$ then it must be $G(d) = A^{-1} d$, and in general we have:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "A(x+\\delta x) & = d+\\delta d \\\\\n",
    "& \\\\\n",
    "A \\delta x & = \\delta d \\\\\n",
    "\\| A \\delta x \\| &= \\| \\delta d\\| \\\\\n",
    "& \\\\\n",
    "\\delta x & = A^{-1} \\delta d \\\\\n",
    "\\| \\delta x \\| & = \\| A^{-1} \\delta d \\| \\\\\n",
    "& \\\\\n",
    "\\| \\delta x \\| & \\leq \\| A^{-1} \\| \\quad\\| \\delta d \\| \\\\\n",
    "\\| d \\| & \\leq \\| A \\| \\quad \\| x \\| \\\\\n",
    "& \\\\\n",
    "\\| \\delta x \\|/\\|x\\| & \\leq \\| A^{-1} \\|\\| A \\| \\quad \\| \\delta d \\|/\\|d\\|\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We see that the **absolute condition number** of this problem is then equal to $\\| A^{-1} \\|$, and the relative condition number is instead equal to $\\| A^{-1} \\|\\| A \\| $. This is what is usually called the **condition number** of a matrix (if nothing is said, it is intended that we are talking about the relative condition number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1933.14691697\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import solve, norm, cond\n",
    "\n",
    "# Construct a random matrix, and check its condition number (fix random seed, so we have always the same number)\n",
    "np.random.seed(101)\n",
    "A = np.random.rand(100,100) \n",
    "\n",
    "K = cond(A) # Linear algebra package of numpy\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number expresses the worst case scenario in relative error we should expect when solving linear systems. If we perturb the data with a unit vector, we should expect the new solution to be at distance $K$ from the original solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Error 2.37596167042e-13\n",
      "Absolute deviation:  0.676705032761\n",
      "Relative deviation:  29.8201041662\n"
     ]
    }
   ],
   "source": [
    "# Construct an artificial solution\n",
    "x = np.random.rand(100)\n",
    "\n",
    "d = A.dot(x); # We could use A*x only if we created a Matrix! This is an ndarray\n",
    "\n",
    "# Verify that we got the right thing...\n",
    "x_test = solve(A,d)\n",
    "error = norm(x_test-x)\n",
    "print(\"Initial Error\", error)\n",
    "\n",
    "# Now perturb d with a unit perturbation, and check the norm of the new solution\n",
    "delta_d = np.random.rand(100)\n",
    "delta_d /= np.linalg.norm(delta_d)\n",
    "\n",
    "xnew = np.linalg.solve(A,d+delta_d)\n",
    "delta_x = xnew-x\n",
    "\n",
    "deviation = np.linalg.norm(delta_x)\n",
    "print(\"Absolute deviation: \", deviation)\n",
    "\n",
    "relative_deviation = (norm(delta_x)/norm(x))/(norm(delta_d)/norm(d))\n",
    "print(\"Relative deviation: \", relative_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in this case that, upon a unit norm perturbation in the data, we obtained a relative perturbation of about 50. The upper limit of this perturbation is given by the relative condition number. The bigger the condition number, the more sensitive to perturbations in the data will be your solution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
